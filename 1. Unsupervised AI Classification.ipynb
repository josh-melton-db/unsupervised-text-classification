{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cf4f382-a9ea-4da8-8ccd-90f70df017a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run on Serverless notebook, or on DBR 16.3 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "111b2852-8a8f-4ccd-ba1f-4e82bcdea1d3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Configurations"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, regexp_replace\n",
    "import random\n",
    "\n",
    "catalog = \"main\" \n",
    "schema = \"default\" \n",
    "source_table = f\"{catalog}.{schema}.pilot_notes\" \n",
    "target_table = f\"{catalog}.{schema}.labeled_pilot_notes\" \n",
    "llm = \"databricks-meta-llama-3-3-70b-instruct\" # can also try databricks-claude-3-7-sonnet, databricks-meta-llama-3-1-8b-instruct\n",
    "training_set_size = 1000 # number of rows to limit your LLM to for unsupervised classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ad9b76f-8f7e-42fb-b52f-f16aaa10f5cc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Generate Dummy Data"
    }
   },
   "outputs": [],
   "source": [
    "classes_and_descriptions = [\n",
    "    (\"PRE-FLIGHT\", \"Aircraft and crew prep before engine start. Examples: Inspecting cargo doors; completing pre-flight checklist.\"),\n",
    "    (\"TAXI_OUT\", \"Moving aircraft from gate to runway. Examples: Taxi via taxiway B; flaps set for takeoff.\"),\n",
    "    (\"TAKEOFF\", \"Aircraft accelerates and lifts off. Examples: Nose up at VR; gear retracted after positive climb.\"),\n",
    "    (\"CLIMB\", \"Gaining altitude to reach cruise. Examples: Throttle set to climb power; monitoring rate of ascent.\"),\n",
    "    (\"CRUISE\", \"Level flight at cruising altitude. Examples: Monitoring instruments; communicating with ATC.\"),\n",
    "    (\"DESCENT\", \"Controlled reduction in altitude. Examples: Initiating descent at TOD; adjusting cabin pressure.\"),\n",
    "    (\"APPROACH\", \"Final phase before landing. Examples: Aligning with runway; configuring flaps and gear.\"),\n",
    "    (\"LANDING\", \"Touchdown and deceleration. Examples: Main gear contact; deploying spoilers and brakes.\"),\n",
    "    (\"TAXI_IN\", \"Moving from runway to parking. Examples: Taxi to gate A4; shutting down unnecessary systems.\"),\n",
    "    (\"POST-FLIGHT\", \"Shutdown and inspection after arrival. Examples: Completing logbook; post-flight walkaround.\"),\n",
    "    (\"UNKNOWN\", \"Unclassified or ambiguous entry. Examples: Notes not tied to a specific flight phase.\")\n",
    "]\n",
    "\n",
    "data = [random.choice(classes_and_descriptions) for _ in range(1000)]\n",
    "df = spark.createDataFrame(data, [\"category\", \"prompt\"])\n",
    "\n",
    "# Use ai_query() to generate pilot notes for each category\n",
    "synthetic_data_df = (\n",
    "    df.withColumn(\n",
    "        \"pilot_notes\", \n",
    "        expr(\n",
    "            f\"ai_query('{llm}', \"\n",
    "            \"concat('No introductory lines like here is a summary of... or during this phase.., \"\n",
    "            \"just role play a pilot writing very objective, direct, concise notes about the following\"\n",
    "            \" topic in about 20 varied words (give or take): ', prompt), \"\n",
    "            \"modelParameters => named_struct('max_tokens', 100, 'temperature', 1))\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "synthetic_data_df.select(\"category\", \"pilot_notes\").write.mode(\"append\").saveAsTable(source_table)\n",
    "source_df = spark.read.table(source_table)\n",
    "source_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57cf0ba0-e019-4854-8fc9-62a5dbb81843",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Unsupervised Classification"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.functions import json_tuple\n",
    "\n",
    "classes = [item[0] for item in classes_and_descriptions]\n",
    "descriptions = [{\"value\": item[0], \"description\": item[1]} for item in classes_and_descriptions]\n",
    "classification_schema_with_confidence = json.dumps({\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"classification\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"classification\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": classes, # Restrict outputs to only the allowed classes\n",
    "                    \"enumDescriptions\": descriptions # Add descriptions to guide outputs\n",
    "                },\n",
    "                \"confidence_level\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"Confidence level of the flight phase classification\",\n",
    "                    \"minimum\": 0,\n",
    "                    \"maximum\": 1\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"classification\", \"confidence_level\"]\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "query = ( # prompt the LLM to classify the pliots notes\n",
    "    f\"ai_query('{llm}', concat('Extract the flight phase classification of these pilot notes: ', pilot_notes), \"\n",
    "    f\"responseFormat => '{classification_schema_with_confidence}')\"\n",
    ")\n",
    "\n",
    "intermediate_df = source_df.withColumn(\"output\", expr(query))\n",
    "parsed_df = (\n",
    "    intermediate_df\n",
    "    .withColumn(\"prediction\", json_tuple(\"output\", \"classification\"))\n",
    "    .withColumn(\"confidence_level\", json_tuple(\"output\", \"confidence_level\"))\n",
    "    .withColumn(\"semantic_similarity\", expr(\"ai_similarity(pilot_notes, prediction)\"))\n",
    "    .withColumn(\"levenshtein_distance\", expr(\"levenshtein(pilot_notes, prediction)\"))\n",
    ")\n",
    "parsed_df.write.mode(\"overwrite\").saveAsTable(target_table)\n",
    "spark.read.table(target_table).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b09822c3-40de-4410-8bca-c9c23ea9af47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1. Unsupervised AI Classification",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
